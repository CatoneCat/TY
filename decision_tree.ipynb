{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树(Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的一个性质是:  \n",
    "基本不需要进行数据预处理, 无需进行特征缩放和特征中心化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成决策树图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,                                #决策树模型\n",
    "        out_file=image_path(\"iris_tree.dot\"),    #图片路径\n",
    "        feature_names=iris.feature_names[2:],    #特征名\n",
    "        class_names=iris.target_names,           #类别名\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片生成后,可以使用graphviz包的工具将其转化为PDF或者PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树图的属性有:  \n",
    "1.gini: 计算分类后,数据无序程度的指标  \n",
    "2.samples : 样本数量  \n",
    "3.value: e.g.[0,49,5]  决策树在该支点的分类结果\n",
    "4.class: 决策树给出的分类结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gini值的计算公式  \n",
    "$\n",
    "G_i = 1 - \\sum\\limits_{k=1}^{n}{{p_{i,k}}^2}\n",
    "$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "其中, $p_{i,k}$表示:  在$i^{th}$node(节点)上,$k$类别在训练集中的比例  \n",
    "e.g.:  \n",
    "$value=[0,49,5]$    \n",
    "$gini = 1 - {(0/54)}^{2} - {(49/54)}^{2} - {(5/54)}^{2} ≈ 0.168  $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn 使用的是CART算法,每一个节点只有2个子节点(question只有yse/no)  \n",
    "然而,其他诸如ID3的算法可以产生更多的子节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 熵(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当熵等于零时,所有的信息都是相同的,在机器学习中,反映包含的所有实例都是同一类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy:  \n",
    "$\\large\n",
    "H_i = -\\sum\\limits_{k=1 \\atop p_{i,k} \\ne 0}^{n}{{p_{i,k}}\\log(p_{i,k})}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$value=[0,49,5]$    \n",
    "$gini = 1 - \\frac{49}{54}log{(\\frac{49}{54})} - \\frac{5}{54}log{(\\frac{5}{54})} ≈ 0.31  $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在大多数情况下,使用gini或熵, 都会得到相似的决策树 , 但gini在运算上稍微快一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估分类概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. $value=[0,49,5]$   \n",
    "将返回 (49/54)≈90.7%的概率为分类2 , (5/54)≈9.3%的概率为分类3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[x1,x2]])  #返回每一个分类的预测概率\n",
    "tree_clf.predict([[x1, x2]])      #返回预测的分类类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART训练算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在每个节点进行分类时,会找出一个最优的($k$, $t_k$)对,来使分类后的数据最有序  \n",
    "$k$表示单一某个特征$k$  \n",
    "$t_k$表示特征$k$的筛选阈值(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART分类的损失函数:   \n",
    "$\n",
    "\\begin{split}\n",
    "&J(k, t_k) = \\dfrac{m_{\\text{left}}}{m}G_\\text{left} + \\dfrac{m_{\\text{right}}}{m}G_{\\text{right}}\\\\\n",
    "&\\text{where }\\begin{cases}\n",
    "G_\\text{left/right} \\text{ measures the impurity of the left/right subset,}\\\\\n",
    "m_\\text{left/right} \\text{ is the number of instances in the left/right subset.}\n",
    "\\end{cases}\n",
    "\\end{split}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了防止决策树的过度拟合,需要对决策树的自由度加以限制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth: 限制决策树的最大深度(默认为None,即无限深度)  \n",
    "min_samples_split: 限制一个节点被拆分前,所拥有的最少实例数(即如果一个节点的实例数过少,则不再继续进行拆分)  \n",
    "min_samples_leaf: 限制一个叶子节点(最终端)所拥有的最少实例数  \n",
    "min_wegiht_fraction_leaf  \n",
    "max_leaf_nodes  \n",
    "max_features  \n",
    "增加min超参数 , 或者 减少max超参数,可以对模型进行正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的回归方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而,正如决策树在分类任务上的表现, 决策树回归也非常容易造成过度拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的不稳定性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树优点:  \n",
    "易于理解和解释, 应用广泛  \n",
    "缺点:  \n",
    "决策树偏向于使用直角的决策边界,因此对数据集的旋转十分敏感  \n",
    "决策树对于训练数据的小变动十分敏感,使得最终得到的模型不稳定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用随机森林算法可以限制决策树的不稳定性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
